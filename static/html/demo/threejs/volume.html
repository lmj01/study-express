<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<script id="vs" type="x-shader/x-vertex">
#version 300 es
precision highp float;

layout(location = 0) in vec3 position;
uniform mat4 umodelview;
uniform mat4 uproject;
void main()
{
    gl_Position = uproject * umodelview * vec4(position, 1.0);
}
</script>
<script id="fs" type="x-shader/x-fragment">
#version 300 es
precision highp float;
precision highp sampler3D;

out vec4 FragColor;
const int maxSamples = 128;

uniform sampler3D uvolume; // 2d data texture

uniform vec3 uBBMin; // box for intersect to make qualifier for ray trace
uniform vec3 uBBMax; 
uniform vec3 uResolution; // for the volume in x,y,z-axis 

uniform float uBrightness;
uniform float uContrast; 
uniform float uSaturation;
uniform float uPower;

uniform mat4 uproject; // project matrix -perspective
uniform mat4 uinvproject; // invert project matrix 
uniform mat4 umodelview; // model view matrix 
uniform mat3 unormal; // normal matrix
uniform vec4 uViewport; 
uniform int uSamples;
// isosurface , it is a surface that represents points of a constant value(density),
// within a volume of space, in other words, it is a level set of
// a continuous function whose dmoain is 3D-space.
// in medical imaging, isosurfaces may be used to represent regions of a particular 
// density in a three-dimensional CT scan, allowing the visulaiztion of internal organs,
// bones, or other structures.
// isosurface is the important role to 3d-vis
uniform float uDensityFactor; 
uniform float uIsoValue;
uniform vec4 uIsoColour;
uniform float uIsoSmooth;
uniform int uIsoWalls;

uniform vec2 uRange;
uniform vec2 uDenMinMax;

//Light moves with camera
const vec3 LightPos = vec3(0.5, 0.5, 5.0);
const float Ambient = 0.2;
const float Diffuse = 0.8;
const vec3 DiffColor = vec3(1.0, 1.0, 1.0);
const vec3 AmbColor = vec3(0.2, 0.2, 0.2);

void lighting(in vec3 pos, in vec3 normal, inout vec3 colour)
{
    // in camera coordinate space
    vec4 vertPos = umodelview * vec4(pos, 1.0);
    vec3 lightDir = normalize(LightPos - vertPos.xyz);
    vec3 lightWeighting = AmbColor + DiffColor * Diffuse * clamp(abs(dot(normal, lightDir)), 0.1, 1.0);
    colour *= lightWeighting;
}

vec3 isoNormal(in vec3 pos, in vec3 shift, in float density)
{
  // gradient vector, made up of the partial derivatives along the three axes;
  // it can be approximated like this 
  vec3 shiftpos = vec3(pos.x + shift.x, pos.y + shift.y, pos.z + shift.z);
  vec3 shiftx = vec3(shiftpos.x, pos.y, pos.z);
  vec3 shifty = vec3(pos.x, shiftpos.y, pos.z);
  vec3 shiftz = vec3(pos.x, pos.y, shiftpos.z);

  //Detect bounding box hit (walls)
  if (uIsoWalls > 0)
  {
    if (pos.x <= uBBMin.x) return vec3(-1.0, 0.0, 0.0);
    if (pos.x >= uBBMax.x) return vec3(1.0, 0.0, 0.0);
    if (pos.y <= uBBMin.y) return vec3(0.0, -1.0, 0.0);
    if (pos.y >= uBBMax.y) return vec3(0.0, 1.0, 0.0);
    if (pos.z <= uBBMin.z) return vec3(0.0, 0.0, -1.0);
    if (pos.z >= uBBMax.z) return vec3(0.0, 0.0, 1.0);
  }

  //Calculate normal
  float x = density - texture(uvolume, shiftx).r;
  float y = density - texture(uvolume, shifty).r;
  float z = density - texture(uvolume, shiftz).r;
  return vec3(x,y,z);
}
// dir ray's direction
// pos ray's position
vec2 rayIntersectBox(vec3 dir, vec3 pos)
{
  // BoundingBox is [0,0,0] to [1,1,1]
  // Intersect ray with bounding box
  vec3 invdir = 1.0 / dir;
  // the pos to uBBMin, uBBMax vector project to the dir length
  vec3 minlen = (uBBMin - pos) * invdir;
  vec3 maxlen = (uBBMax - pos) * invdir;
  // make sure the max is max, min is min
  vec3 rmax = max(maxlen, minlen);
  vec3 rmin = min(maxlen, minlen);
  // back is min, front is max, threejs coordinate is the same
  float back = min(rmax.x, min(rmax.y, rmax.z));
  float front = max(max(rmin.x, 0.0), max(rmin.y, rmin.z));
  return vec2(back, front);
}

vec4 CalcEyeFromWindow(in vec3 windowSpace) 
{
    vec3 ndcPos;
    ndcPos.xy = ((2.0 * windowSpace.xy) - (2.0 * uViewport.xy)) / (uViewport.zw) - 1.0;
    ndcPos.z = (2.0 * windowSpace.z - gl_DepthRange.near - gl_DepthRange.far) / (gl_DepthRange.far - gl_DepthRange.near);

    vec4 clipPos;
    clipPos.w = uproject[3][2] / (ndcPos.z - (uproject[2][2] / uproject[2][3]));
    clipPos.xyz = ndcPos * clipPos.w;

    return uinvproject * clipPos;
}

void main()
{
    //Compute eye space coord from window space to get the ray direction
    // vertex_ndc = projectionMatrix * vertex_eye
    // vertex_ndc = projectionMatrix * viewMatrix * vertex_world
    // vertex_ndc = projectionMatrix * viewMatrix * modelMatrix * vertex_model

    //ObjectSpace *[MV] = EyeSpace *[P] = Clip /w = Normalised device coords ->VP-> Window
    //Window ->[VP^]-> NDC ->[/w]-> Clip ->[P^]-> EyeSpace ->[MV^]-> ObjectSpace
    // NDC all vertex x,y,z component in [-1.0,1.0]
    // the gl_FragCoord ,the location in window space, the x,y,z are the window-space position,
    // the z value will be written to the depth buffer if gl_FragDepth is not written to 
    // 
    vec4 ndcPos;
    // from window coordinate to ndc coordinate, make ndcPos.xy in [-1,1]
    ndcPos.xy = ((2.0 * gl_FragCoord.xy) - (2.0 * uViewport.xy)) / (uViewport.zw) - 1.0; 
    // gl_DepthRange { float near; float far; float diff;}
    ndcPos.z = (2.0 * gl_FragCoord.z - gl_DepthRange.near - gl_DepthRange.far) /
               (gl_DepthRange.far - gl_DepthRange.near);
    ndcPos.w = 1.0;
    // from ndc space to clip space
    vec4 clipPos = ndcPos / gl_FragCoord.w; 
    
    // now WebGL2RenderingContext.uniformMatrix,the second parameter transpose now must be false, 
    // it accept the column-major order matrix
    // transpose is make Row-major to Column-major order
    // umodelview is camera.matrixWorldInverse
    // the volume-mesh has the modelViewMatrix(threejs provide)
    mat4 invmodelview = transpose(umodelview);
    //    transpose(A)*B = identity
    // => transpose(A) = identity * inverse(B)
    // => transpose(A) = inverse(B)
    // => A = transpose(invverse(B))
    // here invmodelview work for the normalize when change the different view
    
    // the other explain:
    // a plane defined by n * x + d = 0, where n is the normal
    // now transform the plane by some matrix M, in other words,
    // find the new plane satisfied n' * Mx + d' = 0
    // the two plane equations equal, so set d' = d and subtract it get 
    // n' * Mx = n * x, in matrix notation is this:
    // => n'^TMx = n^Tx
    // => n'^T = n^T 
    // => n'^T = n^T*inverse(M) 
    // => n' = transpose(n^T * inverse(M)) 
    // => n' = transpose(inverse(M))*n
    // some reason think the normal is cross product by triangle points, may by shear when non-uniform scale

    // from clip space to camera space, it is the ray-direction
    vec3 rayDirection = normalize((invmodelview * uinvproject * clipPos).xyz);    

    //Ray origin from the camera position
    vec4 camPos = -vec4(umodelview[3]);  // 4th column of modelview matrix, the position in the matrix
    vec3 rayOrigin = (invmodelview * camPos).xyz; // the camera position in the camera space
    
    //Intersect ray with bounding box
    vec2 intersection = rayIntersectBox(rayDirection, rayOrigin);
    //Subtract small increment to avoid errors on front boundary
    intersection.y -= 0.000001;
    //Discard points outside the box (no intersection)
    if (intersection.x <= intersection.y) {
        discard;
    }
    
    // ray from near to far 
    vec3 rayStart = rayOrigin + rayDirection * intersection.y; // front
    vec3 rayStop = rayOrigin + rayDirection * intersection.x; // back

    //Calc the max step, from the Box min position to the box max position
    float stepSize = 1.732 / float(uSamples); //diagonal of [0,1] normalised coord cube = sqrt(3)
    vec3 step = normalize(rayStop - rayStart) * stepSize; // the step length for every step
    vec3 pos = rayStart;

    float T = 1.0;
    vec3 colour = vec3(0.0);
    bool inside = false;
    vec3 shift = 
        //uIsoSmooth / uResolution;
        vec3(0.1, 0.1, 0.1);
    //Number of samples to take along this ray before we pass out back of volume...
    float travel = distance(rayStop, rayStart) / stepSize;
    int samples = int(ceil(travel));
    float range = uRange.y - uRange.x;
    if (range <= 0.0) range = 1.0;
    //Scale isoValue, the equal density surface value,
    float isoValue = uRange.x + uIsoValue * range;
    
    //Raymarch, front to back
    for (int i=0; i < maxSamples; ++i) {
        //Render samples until we pass out back of cube or fully opaque
        if (i == samples || T < 0.01) break;
        if (i == samples) break;
        if (all(greaterThanEqual(pos, uBBMin)) && all(lessThanEqual(pos, uBBMax))) 
        {
            // Get density, because texture is luminance
            float density = texture(uvolume, pos).r;
#define ISOSURFACE
#ifdef ISOSURFACE
            // the voxel are not drawn which that less than constant value(iosValue)
            //Passed through isosurface?
            if (isoValue > uRange.x && ((!inside && density >= isoValue) || (inside && density < isoValue))) 
            {
                inside = !inside;
                //Find closer to exact position by iteration
                //http://sizecoding.blogspot.com.au/2008/08/isosurfaces-in-glsl.html
                /*
                * For each pixel
                *    step along ray until surface is hit
                *    find normal
                *    light and output colour
                */
                float exact;
                float a = intersection.y + (float(i) * stepSize);
                float b = a - stepSize;
                for (int j = 0; j < 8; j++) {
                    exact = (b + a) * 0.5;
                    pos = rayDirection * exact + rayOrigin;
                    density = texture(uvolume, pos).r;
                    if (density - isoValue < 0.0) {
                        b = exact;
                    } else {
                        a = exact;
                    }
                }
            
                //Skip edges unless flagged to draw
                if (uIsoWalls > 0 || (all(greaterThanEqual(pos, uBBMin)) && all(lessThanEqual(pos, uBBMax)))) {
                    
                    vec4 value = vec4(uIsoColour.rgb, 1.0);
                
                    // threejs normalMatrix use for not calculation normal, or result is non-unit scaling 
                    vec3 normal = normalize(unormal * isoNormal(pos, shift, density));
                    
                    vec3 light = value.rgb;
                    lighting(pos, normal, light);
                    //Front-to-back blend equation
                    colour += T * uIsoColour.a * light;
                    T *= (1.0 - uIsoColour.a);
                }
            }
#endif
            if (uDensityFactor > 0.0 ) {
                //Normalise the density over provided range
                density = (density - uRange.x) / range;
                density = clamp(density, 0.0, 1.0);
                if (density < uDenMinMax[0] || density > uDenMinMax[1]) {
                    //Skip to next sample...
                    pos += step;
                    continue;
                }
                
                density = pow(density, uPower); //Apply power
                vec4 value = vec4(density);
                value *= uDensityFactor * stepSize;
                //Color
                colour += T * value.rgb;
                //Alpha
                T *= 1.0 - value.a;
            }
        }
         
        //Next sample...
        pos += step;
    }

    //Apply brightness, saturation & contrast
    if (true) { 
        colour += uBrightness;
        const vec3 LumCoeff = vec3(0.2125, 0.7154, 0.0721);
        vec3 AvgLumin = vec3(0.5, 0.5, 0.5);
        vec3 intensity = vec3(dot(colour, LumCoeff));
        colour = mix(intensity, colour, uSaturation);
        colour = mix(AvgLumin, colour, uContrast);
    }
    if (T > 0.95) {
        discard;
    }
    FragColor = vec4(colour, 1.0 - T);

#define WRITE_DEPTH
#ifdef WRITE_DEPTH
    /* write the depth !Not supported in WebGL without extension */
    vec4 clip_space_pos = uproject * umodelview * vec4(rayStart, 1.0);
    float ndc_depth = clip_space_pos.z / clip_space_pos.w;
    gl_FragDepth = (((gl_DepthRange.far - gl_DepthRange.near) * ndc_depth) +
        gl_DepthRange.near + gl_DepthRange.far) / 2.0;
#endif
}
</script>
<script id="vs2" type="x-shader/x-vertex">
#version 300 es

layout(location=0) in vec3 position;

uniform mat4 umodelview;
uniform mat4 uproject;
uniform mat4 uview; // camera.matrixWorldInverse

// return the world space coordinate
out vec4 v_nearpos;
out vec4 v_farpos;
out vec3 v_position;
out vec4 v_campos;

void main(void)
{
    // prepare transforms to map to camera view
    mat4 viewtransform = uview;
    mat4 viewtransformi = inverse(uview);

    // project local vertex coordinate to camra position
    // then do a step backward(in camera coord) to the near clipping plane,
    // and project back. do the same for the far clipping plane. this
    // gives us all the information we need to calculate the ray
    // and truncate it to the viewing cone
    vec4 position4 = vec4(position, 1.0);
    vec4 pos_in_camera = viewtransform * position4;
    v_campos = pos_in_camera;

    // intersection of ray and near clipping plane(z=-1 in the clip coords)
    pos_in_camera.z = -pos_in_camera.w;
    v_nearpos = viewtransformi * pos_in_camera;

    // intersection of ray and far clipping plane(z=+1 in the clip coords)
    pos_in_camera.z = pos_in_camera.w;
    v_farpos = viewtransformi * pos_in_camera;

    //
    v_position = position;
    gl_Position = uproject * umodelview * position4;
}
</script>
<script id="fs2" type="x-shader/x-fragment">
#version 300 es
precision highp float;
precision highp int;
precision highp sampler3D;
precision highp sampler2D;

uniform vec3 usize;
uniform int urenderstyle;
uniform float urenderthreshold;
uniform vec2 uclim;

uniform sampler3D uvolume;
uniform sampler2D ucolormap;

in vec4 v_nearpos;
in vec4 v_farpos;
in vec3 v_position;
in vec4 v_campos;
out vec4 fragcolor;

// the maximum distance through ourer rendering volume is sqrt(3)
// max-steps = max-len * Math.sqrt(3)
const int MAX_STEPS = 887; // 887 for 512^3, 1174 for 1024^3
const int REFINEMENT_STEPS = 4;
const float relative_step_size = 1.0;
const vec4 ambient_color = vec4(0.2, 0.4, 0.2, 1.0);
const vec4 diffuse_color = vec4(0.8, 0.2, 0.2, 1.0);
const vec4 specular_color = vec4(1.0, 1.0, 1.0, 1.0);
const float shininess = 40.0;

float sample1(in vec3 pos);
vec4 apply_colormap(in float val);
vec4 add_lighting(in float val, in vec3 loc, in vec3 step, in vec3 view_ray); 

void cast_mip(in vec3 start_loc, in vec3 step, in int nsteps, in vec3 view_ray)
{
    float max_val = -1e6;
    int max_i = 100;
    vec3 loc = start_loc;

    // 
    for (int iter=0; iter<MAX_STEPS; ++iter) {
        if (iter >= nsteps) break;

        float val = sample1(loc);
        // Apply MIP operation
        if (val > max_val) {
            max_val = val;
            max_i = iter;
        }
        // advance location deeper into the volume
        loc += step;
    }
    // refine location, gives crispier images
    vec3 iloc = start_loc + step * (float(max_i) - 0.5);
    vec3 istep = step / float(REFINEMENT_STEPS);
    for (int i=0; i<REFINEMENT_STEPS; ++i) {
        max_val = max(max_val, sample1(iloc));
        iloc += istep;
    }
    // resolve final color
    fragcolor = apply_colormap(max_val);
}

void cast_iso(in vec3 start_loc, in vec3 step, in int nsteps, in vec3 view_ray)
{
    fragcolor = vec4(0.0); // init transparent
    vec4 color3 = vec4(0.0); // final color
    vec3 dstep = 1.5 / usize; // step to sample derivative
    vec3 loc = start_loc;

    float low_threshold = urenderthreshold - 0.02 * (uclim[1] - uclim[0]);
    for (int iter=0; iter<MAX_STEPS;++iter) {
        if (iter >= nsteps) break;

        float val = sample1(loc);

        if (val > low_threshold) {
            // take the last interval in smaller steps
            vec3 iloc = loc - 0.5 * step;
            vec3 istep = step / float(REFINEMENT_STEPS);
            for (int i=0; i<REFINEMENT_STEPS;++i) {
                val = sample1(iloc);
                if (val > urenderthreshold) {
                    fragcolor = add_lighting(val, iloc, dstep, view_ray);
                    return;
                }
                iloc += istep;
            }
        }
        // advance location deeper into the volume
        loc += step;
    }
}

float sample1(in vec3 texcoords)
{
    // sample float value from a 3d texture. assume inensity data
    return texture(uvolume, texcoords.xyz).r;
}

vec4 apply_colormap(in float val)
{
    val = (val - uclim[0]) / (uclim[1] - uclim[0]);
    return texture(ucolormap, vec2(val, 0.5));
}

vec4 add_lighting(in float val, vec3 loc, in vec3 step, in vec3 view_ray)
{
    // calculate color by incorporating lighting

    // view direction 
    vec3 v = normalize(view_ray);

    // calculate normal vector fram gradient
    vec3 n;
    float v1, v2;
    // x
    v1 = sample1(loc + vec3(-step[0], 0.0, 0.0));
    v2 = sample1(loc + vec3( step[0], 0.0, 0.0));
    n[0] = v1 - v2;
    val = max(max(v1, v2), val);
    // y
    v1 = sample1(loc + vec3(0.0, -step[1], 0.0));
    v2 = sample1(loc + vec3(0.0,  step[1], 0.0));
    n[1] = v1 - v2;
    val = max(max(v1, v2), val);
    // z
    v1 = sample1(loc + vec3(0.0, 0.0, -step[2]));
    v2 = sample1(loc + vec3(0.0, 0.0,  step[2]));
    n[2] = v1 - v2;
    val = max(max(v1, v2), val);

    float gm = length(n); // gradient magnitude
    n = normalize(n);

    // flip normal so ti points towrads viewer
    float nselect = float(dot(n, v) > 0.0);
    n = (2.0 * nselect - 1.0) * n; // == nselect * n - (1.0 - nselect) * n;

    // init colors
    vec4 ambient_color = vec4(0.2, 0.4, 0.2, 1.0);
    vec4 diffuse_color = vec4(0.8, 0.2, 0.2, 1.0);
    vec4 specular_color = vec4(0.0);

    // note: could allow multiple lights
    for (int i=0; i<1; ++i) {
        // get light direction(make sure to prevent zero devision)
        vec3 ray = normalize(view_ray); // lightDirs[i]
        float lightEnabled = float(length(ray) > 0.0);
        ray = normalize(ray + (1.0 - lightEnabled));

        // calculate lighting properties
        float lambertTerm = clamp(dot(n, ray), 0.0, 1.0);
        vec3 halfV = normalize(ray + v); // halfway vector
        float specularTerm = pow(max(dot(halfV, n), 0.0), shininess);

        // calculate mask
        float mask1 = lightEnabled;
        // calculate colors
        ambient_color += mask1 * ambient_color; // gl_LightSource[i].ambient;
        diffuse_color += mask1 * lambertTerm;
        specular_color += mask1 * specularTerm * specular_color;
    }

    // calculate final color by componing different components
    vec4 final_color;
    vec4 color = apply_colormap(val);
    final_color = color * (ambient_color + diffuse_color) + specular_color;
    final_color.a = color.a;
    return final_color;
}

void main(void)
{

    // normalize clipping plane info
    vec3 farpos = v_farpos.xyz / v_farpos.w;
    vec3 nearpos = v_nearpos.xyz / v_nearpos.w;

    // calculate unit vector pointing in the view direction through this fragment
    vec3 view_ray = normalize(nearpos.xyz - farpos.xyz);

    // compute the (negative) distance to the front surface or near clipping plane,
    // v_position is the back fo the cuboid, so the initial distance calculated in the dot
    // product below is the distance from near clip plane to the back of the cuboid
    float distanceval = dot(nearpos - v_position, view_ray);

    // between usize and (0,0,0) the max distance
    distanceval = max(distanceval, min(
        (-0.5 - v_position.x) / view_ray.x,
        (usize.x - 0.5 - v_position.x) / view_ray.x));
    distanceval = max(distanceval, min(
        (-0.5 - v_position.y) / view_ray.y,
        (usize.y - 0.5 - v_position.y) / view_ray.y));
    distanceval = max(distanceval, min(
        (-0.5 - v_position.z) / view_ray.z,
        (usize.z - 0.5 - v_position.z) / view_ray.z));

    // now we have starting position on the front surface
    vec3 front = v_position + view_ray * distanceval;
    
    // decide how many steps to take
    int nsteps = int(-distanceval / relative_step_size + 0.5);
    if (nsteps < 1) {
        fragcolor = vec4(0.0, 0.0, 1.0, 0.8);
        //return;
        discard;
    }

    // get starting location and step vector in texture coordinates
    vec3 step = ((v_position - front) / usize) / float(nsteps);
    vec3 start_loc = front / usize;

    // for testing: show the number of steps, this helps to establish
    // whether teh rays are correctly oriented
    if (urenderstyle == 0) {
        cast_mip(start_loc, step, nsteps, view_ray);
    } else if (urenderstyle == 1) {
        cast_iso(start_loc, step, nsteps, view_ray);
    }

    if (fragcolor.a < 0.05) {
        fragcolor = vec4(1.0, 0.0, 0.0, 0.2);
        discard;
    } 
}
</script>
<script id="vsDepth" type="x-shader/x-vertex">
#version 300 es

layout(location=0) in vec3 position;

uniform mat4 umodelview;
uniform mat4 uproject;
uniform float depth;
uniform vec2 size;

out vec3 vUv;

void main(void)
{
    gl_Position = uproject * umodelview * vec4(position, 1.0);
    // convert position.xy to 1.0 to 0.0
    vUv.xy = position.xy / size + 0.5;
    //vUv.xy = position.xy + 0.5;
    vUv.y = 1.0 - vUv.y; // original data is upside down
    vUv.z = depth;
}
</script>
<script id="fsDepth" type="x-shader/x-fragment">
#version 300 es
precision highp float;
precision highp int;
precision highp sampler3D;

uniform sampler3D uvolume;
in vec3 vUv;
out vec4 fragcolor;

void main(void)
{
    vec4 color = texture(uvolume, vUv);
    fragcolor = vec4(color.rrr * 1.5, 0.5);
    //fragcolor = vec4(1.0, 0.0, 0.0, 0.5);
}
</script>
<script id="vsline" type="x-shader/x-vertex">
#version 300 es

layout(location=0) in vec3 position;
layout(location=1) in vec4 color;

uniform mat4 umodelview;
uniform mat4 uproject;

out vec4 vcolor;

void main(void)
{
    gl_Position = uproject * umodelview * vec4(position, 1.0);
    vcolor = color;
}
</script>
<script id="fsline" type="x-shader/x-fragment">
#version 300 es
precision highp float;

in  vec4 vcolor;
out vec4 fragcolor;

void main(void)
{
    fragcolor = vcolor;
}
</script>
<style>
    .description {
        position: absolute;
        z-index: 5;
    }
    canvas {
        position: absolute;
        border: 1px solid red;        
        width: 100%;
        height: 100%;
    }    
</style>
<script src="/js/threejs/three.min.js"></script>
<script src="/js/threejs/OrbitControls.js"></script>
<script src="/js/lib/jszip.min.js"></script>
<script src="/js/lib/dat.gui.min.js"></script>
</head>
<body>
    <div>
        <canvas id="demo"></canvas>
    </div>
    <div class="description">
        <p><a href="https://github.com/OKaluza/sharevol">Lightweight
         volume slicing and rendering in webGL</a> portable to threejs with texture3D
         <br>
         <a href="https://www.khronos.org/opengl/wiki/Compute_eye_space_from_window_space">
             Compute eye space from window space</a><br>
         <a href="https://mynameismjp.wordpress.com/2010/09/05/position-from-depth-3/">
             Position from depth 3: back in the habit</a><br>
         <a href="https://nbertoa.wordpress.com/2017/01/09/how-can-i-find-the-pixel-space-coordinates-of-a-3d-point-part-1/">
             how can i find the pixel space coordinates of a 3d point part 1</a><br>
         <a href="https://almarklein.org/volume_rendering.html">
            Volume rendering in Vispy</a><br>
        </p>
    </div>
    <script>
        
        let canvas = document.getElementById('demo');
        let ctx = canvas.getContext( 'webgl2', { antialias: true } )
        if( ctx == null ) { alert( 'requires webgl2 support!' ) }
        
        let scene = new THREE.Scene();
        let renderer = new THREE.WebGLRenderer({canvas:canvas, context:ctx, antialias:true});
        renderer.setSize(canvas.clientWidth, canvas.clientHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        //renderer.setClearColor(new THREE.Color(0xffffffff));
        renderer.setViewport(0, 0, canvas.clientWidth, canvas.clientHeight);

        let aspectRatio = 
            //window.innerWidth / window.innerHeight;
            canvas.clientWidth / canvas.clientHeight;
        let camera;
        if (true) {
            camera = new THREE.PerspectiveCamera(45, 
                aspectRatio,
                0.01, 10000);
            camera.position.set(257, 597, 1604);
        } else {
            let frustum = { h: 256, };
            camera = new THREE.OrthographicCamera(
                -frustum.h * aspectRatio / 2, 
                 frustum.h * aspectRatio / 2,
                 frustum.h / 2, -frustum.h / 2, 
                 -0.1, 100000);
            camera.up.set(0,1,0);
            camera.position.set(2, 2, -20);
        }

        let light = new THREE.DirectionalLight(0xff0000, 0.5);
        light.position.set(100, 100, 200);
        scene.add(light);

        let m;
        let m2, 
            depthStep = 1 / (109 * 3), 
            m3,m4;
        let volmesh;
        let volume={
                xmin:0,
                ymin:0,
                zmin:0,
                xmax:1,
                ymax:1,
                zmax:1,
                brightness: 0.0,
                contrast: 1.0,
                saturation: 1.0,
                power: 1.0,
                samples: 250,
                density: 3.0,
                isovalue: 0.3,
                isocolor: [255, 255, 255, 1],
                isosmooth: 1.0,
                isowalls: true,
                minclip:0.0,
                maxclip:1.0,
                resx: 256,
                resy: 256,
                resz: 109,
            },
            gui = new dat.GUI({autoPlace:false});
        gui.domElement.style.zIndex = 20;
        gui.domElement.style.position = 'absolute';
        gui.domElement.style.right = 0;
        canvas.parentElement.appendChild(gui.domElement);
        let f0 = gui.addFolder('Clip planes(Box-min-max)');
        f0.add(volume, 'xmin', 0.0, 1.0, 0.01);
        f0.add(volume, 'ymin', 0.0, 1.0, 0.01);
        f0.add(volume, 'zmin', 0.0, 1.0, 0.01);
        f0.add(volume, 'xmax', 0.0, 1.0, 0.01);
        f0.add(volume, 'ymax', 0.0, 1.0, 0.01);
        f0.add(volume, 'zmax', 0.0, 1.0, 0.01);
        f0.add(volume, 'minclip', 0.0, 1.0, 0.01);
        f0.add(volume, 'maxclip', 0.0, 1.0, 0.01);
        gui.add(volume, 'brightness', -1.0, 1.0, 0.05);
        gui.add(volume, 'contrast', 0.0, 2.0, 0.05);
        gui.add(volume, 'saturation', 0.0, 2.0, 0.05);
        gui.add(volume, 'power', 0.0, 5.0, 0.05);
        gui.add(volume, 'samples', 32, 1024, 1);
        gui.add(volume, 'density', 0.0, 50.0, 1.0);
        let f1 = gui.addFolder('IsoSurface');
        f1.add(volume, 'isovalue', 0.0, 1.0, 0.01);
        f1.addColor(volume, 'isocolor');
        f1.add(volume, 'isosmooth', 0.1, 3.0, 0.1);
        f1.add(volume, 'isowalls', 0.0, 1.0, 0.01);
        
        let volconfig = {
            clim1: 0,
            clim2: 1,
            renderstyle: 'mip',
            isothreshold: 0.15,
            colormap: 'gray'
        };
        let f = gui.addFolder('threejs-volume');
        f.add(volconfig, 'clim1', 0, 1, 0.01);
        f.add(volconfig, 'clim2', 0, 1, 0.01);
        f.add(volconfig, 'colormap', {gray:'gray',viridis:'viridis'});
        f.add(volconfig, 'renderstyle', {mip:'mip',iso:'iso'});
        f.add(volconfig, 'isothreshold', 0, 1, 0.01);
        let voltextures = {
            viridis: new THREE.TextureLoader().load('./cm_viridis.png', renderer),
            gray: new THREE.TextureLoader().load('./cm_gray.png', renderer)
        };

        let orbitControl = new THREE.OrbitControls(camera, renderer.domElement);
        orbitControl.maxPolarAngle = Math.PI * 2;
        orbitControl.target.set(0, 0, 0);
        orbitControl.update();

        let axesHelper = new THREE.AxesHelper(200);
        scene.add(axesHelper);
        
        function loadRaw() {
            (new Promise((resolve, reject)=>{
                let xhr = new XMLHttpRequest();
                xhr.open('GET', './volume/head256x256x109.zip', true);
                xhr.responseType = 'blob';
                xhr.onloadend = function() {
                    let fr = new FileReader();
                    fr.onload = function() {
                        console.log(fr);
                        let len = fr.result.byteLength;
                        let buffer = new Uint8Array(fr.result, 0, len);
                        resolve({buffer, len});
                    }
                    fr.readAsArrayBuffer(xhr.response);
                }
                xhr.send();
            })).then((data)=>{
                return JSZip.loadAsync(data.buffer)
            }).then(zip=>{
                let file = zip.files['head256x256x109'];
                return file._data.compressedContent;
            }).then(buffer=>{                
                let texture = new THREE.DataTexture3D(buffer, volume.resx, volume.resy, volume.resz);
                texture.format = THREE.RedFormat;
                texture.type = THREE.UnsignedByteType;
                texture.type = THREE.FloatType;
                texture.minFilter = texture.magFilter = THREE.LinearFilter;
                texture.unpackAlignment = 1;
                texture.needsUpdate = true;

                let materialVolume = new THREE.RawShaderMaterial({
                    uniforms: {
                        uvolume:{value:texture},
                        umodelview:{value:new THREE.Matrix4()},
                        uproject:{value:new THREE.Matrix4()},
                        uinvproject:{value:new THREE.Matrix4()},
                        unormal:{value:new THREE.Matrix3()},

                        uBBMin:{value:new THREE.Vector3(0,0,0)},
                        uBBMax:{value:new THREE.Vector3(1,1,1)},
                        uResolution:{value:new THREE.Vector3(volume.resx, volume.resy, volume.resz)},
                        uBrightness:{value:-0.11780890196982163},
                        uContrast:{value: 1},
                        uSaturation:{value:1.0},
                        uPower:{value:5},
                        uViewport:{value:new THREE.Vector4(0, 0, 
                                //canvas.clientWidth, canvas.clientHeight
                                volume.resx, volume.resy
                                )},
                        uSamples:{value:256},
                        uDensityFactor:{value:3},
                        uIsoValue:{value:0.45},
                        uIsoColour:{value:new THREE.Vector4(1.0, 1.0, 0.0, 1.0)},
                        uIsoSmooth:{value:0.5045783843331688},
                        uIsoWalls:{value:true},
                        uRange:{value:new THREE.Vector2(0.0, 1.0)},
                        uDenMinMax:{value:new THREE.Vector2(0.0, 1.0)},
                    },
                    vertexShader: document.getElementById('vs').textContent.trim(),
                    fragmentShader: document.getElementById('fs').textContent.trim(),
                    side: THREE.DoubleSide,
                });
                let materialPlane = new THREE.RawShaderMaterial({
                    uniforms: {
                        uvolume:{value:texture},
                        depth:{value:0},
                        size:{value:new THREE.Vector2(256,256)},
                        umodelview:{value:new THREE.Matrix4()},
                        uproject:{value:new THREE.Matrix4()}
                    },
                    vertexShader: document.getElementById('vsDepth').textContent.trim(),
                    fragmentShader: document.getElementById('fsDepth').textContent.trim(),
                    side: THREE.DoubleSide,
                });
                let materialCube = new THREE.RawShaderMaterial({
                    uniforms: {
                        umodelview: {value:new THREE.Matrix4()},
                        uproject: {value:new THREE.Matrix4()}
                    },
                    vertexShader: document.getElementById('vsline').textContent.trim(),
                    fragmentShader: document.getElementById('fsline').textContent.trim(),
                    side: THREE.DoubleSide,
                });
                let materialLine = new THREE.RawShaderMaterial({
                    uniforms: {
                        umodelview: {value:new THREE.Matrix4()},
                        uproject: {value:new THREE.Matrix4()}
                    },
                    vertexShader: document.getElementById('vsline').textContent.trim(),
                    fragmentShader: document.getElementById('fsline').textContent.trim(),
                    side: THREE.DoubleSide,
                });
                        let vertexArray = new Float32Array([
                            // front
                            -1.0, -1.0,  1.0,  
                             1.0, -1.0,  1.0,
                             1.0,  1.0,  1.0,
                            -1.0,  1.0,  1.0,
                            // back
                            -1.0, -1.0, -1.0,
                             1.0, -1.0, -1.0,
                             1.0,  1.0, -1.0,
                            -1.0,  1.0, -1.0
                        ]);
                        let colorArray = new Float32Array([
                            // front
                            1.0, 0.0, 0.0, 1.0,
                            0.0, 1.0, 0.0, 1.0,
                            0.0, 0.0, 1.0, 1.0,
                            1.0, 0.0, 1.0, 1.0,
                            // back
                            1.0, 0.0, 0.0, 1.0,
                            0.0, 1.0, 0.0, 1.0,
                            0.0, 0.0, 1.0, 1.0,
                            1.0, 0.0, 1.0, 1.0

                        ]);
                        let indexArray = new Uint8Array([
                            // front
                            0, 1, 2,
                            2, 3, 0,
                            // right
                            1, 5, 6,
                            6, 2, 1,
                            // back
                            7, 6, 5,
                            5, 4, 7,
                            // left
                            4, 0, 3,
                            3, 7, 4,
                            // bottom
                            4, 5, 1,
                            1, 0, 4,
                            // top
                            3, 2, 6,
                            6, 7, 3
                        ]); 
                        //vertexArray.map((e,i,a)=>a[i]=e*128.0);
                        //vertexArray.map((e,i,a)=>a[i]=(e+0.5));
                let gCube = new THREE.BufferGeometry();
                gCube.addAttribute('position', new THREE.BufferAttribute(vertexArray, 3));
                gCube.setIndex(new THREE.BufferAttribute(indexArray, 1));
                if (false) {
                    m = new THREE.Mesh(gCube, materialVolume);
                    m.name = 'planeVolume';
                    m.position.set(0,0,0);
                    m.geometry.computeBoundingBox();
                    //m.translateX(20);
                    let tmp = new THREE.Matrix4();
                    tmp.makeTranslation(2,0,0);
                    tmp.makeScale(1,-1,1);
                    m.applyMatrix(tmp);
                    m.matrixAutoUpdate = true;
                    m.matrixWorldNeedsUpdate = true;
                    m.updateMatrix();
                    m.ok = true;
                    scene.add(m);
                    if (false) {
                        let gCubeTmp = new THREE.BufferGeometry();
                        gCubeTmp.addAttribute('position', new THREE.BufferAttribute(vertexArray, 3));
                        gCubeTmp.addAttribute('color', new THREE.BufferAttribute(colorArray,4));
                        gCubeTmp.setIndex(new THREE.BufferAttribute(indexArray, 1));

                        m3 = new THREE.Mesh(gCubeTmp, materialCube);
                        m3.name = 'cube-wireframe';
                        m3.position.set(0,0,0);
                        m3.geometry.computeBoundingBox();
                        //m3.translateZ(2);
                        m3.updateMatrix();
                        m3.ok = true;
                        scene.add(m3);
                    }
                    if (false) {
                        let gLine = new THREE.BufferGeometry();
                        gLine.addAttribute('position', new THREE.BufferAttribute(vertexArray, 3));
                        gLine.addAttribute('color', new THREE.BufferAttribute(colorArray, 4));
                        m4 = new THREE.Line(gLine, 
                                new THREE.LineBasicMaterial({vertexColors:THREE.VertexColors})
                                //materialLine
                                );
                        m4.position.set(0, 0, 0);
                        m4.updateMatrix();
                        m4.ok = true;
                        scene.add(m4);
                    }
                }
                if (false) {
                    m2 = new THREE.Mesh(
                            new THREE.PlaneBufferGeometry(256,256, 1, 1), 
                            materialPlane);
                    m2.name = 'demo-2';
                    //m2.scale.set(0.01, 0.01, 0.01);
                    //m2.translateX(-4);
                    m2.translateX(-250);
                    m2.updateMatrix();
                    m2.ok = true;
                    scene.add(m2);
                }

                let volgeometry = new THREE.BoxBufferGeometry(
                        //volume.resx, volume.resy, volume.resz
                        volume.resx/2, volume.resy/2, volume.resz/2
                        );
                //volgeometry.translate(volume.resx/2-0.5, volume.resy/2-0.5, volume.resz/2-0.5);
                volmesh = new THREE.Mesh(volgeometry, 
                        new THREE.RawShaderMaterial({
                            uniforms: {
                                uvolume:{value:texture},
                                ucolormap:{value: voltextures[volconfig.colormap]},
                                usize:{value:new THREE.Vector3(volume.resx, volume.resy, volume.resz)},
                                uclim:{value:new THREE.Vector2()},
                                urenderstyle:{value:1},
                                urenderthreshold:{value:0.5},
                                umodelview:{value: new THREE.Matrix4()},
                                uproject:{value: camera.projectionMatrix},
                                uview:{value: camera.matrixWorldInverse}
                            },
                            vertexShader: document.getElementById('vs2').textContent.trim(),
                            fragmentShader: document.getElementById('fs2').textContent.trim(),
                            side: THREE.DoubleSide // the volume shader uses the backface as its reference point                       
                        })
                );
                volmesh.ok = true;
                let tmp = new THREE.Matrix4();
                tmp.makeTranslation(2,0,0);
                tmp.makeScale(1,-1,1);
                //volmesh.applyMatrix(tmp);
                volmesh.matrixAutoUpdate = true;
                volmesh.matrixWorldNeedsUpdate = true;
                //volmesh.scale.set(0.01, 0.01, 0.01);
                //volmesh.translateX(4);
                //volmesh.position.set(-128.5, -128.5, 128);
                volmesh.updateMatrix();
                scene.add(volmesh);
            })
        }
        function updateUniforms() {

            if (m && m.ok) {
                let u = m.material.uniforms;
                u.umodelview.value = m.modelViewMatrix;
                //u.umodelview.value = camera.matrixWorldInverse;
                u.uproject.value = camera.projectionMatrix;
                u.unormal.value = m.normalMatrix;
                u.uinvproject.value = camera.projectionMatrixInverse;
                
                u.uBBMin.value = new THREE.Vector3(volume.xmin, volume.ymin, volume.zmin);
                u.uBBMax.value = new THREE.Vector3(volume.xmax, volume.ymax, volume.zmax);
                u.uDenMinMax.value = new THREE.Vector2(volume.minclip, volume.maxclip);
                u.uPower.value = volume.power;
                u.uDensityFactor.value = volume.density;
                u.uSamples.value = volume.samples;
                u.uBrightness.value = volume.brightness;
                u.uContrast.value = volume.contrast;
                u.uSaturation.value = volume.saturation;
                
                u.uIsoValue.value = volume.isovalue;
                u.uIsoColour.value = new THREE.Vector4(
                        volume.isocolor[0] / 255.0,
                        volume.isocolor[1] / 255.0,
                        volume.isocolor[2] / 255.0,
                        volume.isocolor[3]);
                u.uIsoSmooth.value = volume.isosmooth;
                u.uIsoWalls.value = volume.isowalls;
            }
            if (m2 && m2.ok) {
                let u = m2.material.uniforms;
                u.umodelview.value = m2.modelViewMatrix;
                u.uproject.value = camera.projectionMatrix;
                let val = u.depth.value;
                val += depthStep;
                if (val > 1.0 || val < 0.0) {
                    if (val > 1.0) val = 2.0 - val;
                    if (val < 0.0) val = -val;
                    depthStep = -depthStep;
                }
                u.depth.value = val;
            }
            if (m3 && m3.ok) {
                let u = m3.material.uniforms;
                u.umodelview.value = m3.modelViewMatrix;
                u.uproject.value = camera.projectionMatrix;
            }
            if (m4 && m4.ok) {
                let u = m4.material.uniforms;
                u.umodelview.value = m4.modelViewMatrix;
                u.uproject.value = camera.projectionMatrix;

                m4.rotation.x += 0.01;
                m4.rotation.y += 0.01;
            }
            if (volmesh && volmesh.ok) {
                let u = volmesh.material.uniforms;
                
                u.umodelview.value = volmesh.modelViewMatrix;
                u.uproject.value = camera.projectionMatrix;
                u.uview.value = camera.matrixWorldInverse;
                
                u.uclim.value.set(volconfig.clim1, volconfig.clim2);
                u.urenderstyle.value = volconfig.renderstyle == 'mip'?0:1;
                u.urenderthreshold.value = volconfig.isothreshold;
                u.ucolormap.value = voltextures[volconfig.colormap];

                volmesh.rotation.x += 0.01;
                volmesh.rotation.y += 0.01;
            }
        }
        function updateFrame() {
            requestAnimationFrame(updateFrame);

            orbitControl.update();

            renderer.render(scene, camera);

            updateUniforms();
        }
        updateFrame();
        loadRaw();
    </script>        
</body>
</html>
